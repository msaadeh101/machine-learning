{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Feature Engineering Pipeline\n",
    "\n",
    "This notebook demonstrates production-ready feature engineering practices for MLOps workflows.\n",
    "It includes data validation, feature creation, transformation pipelines, and monitoring components.\n",
    "\n",
    "The purpose of this notebook is to prepare high-quality, validated, production ready features. A model is only as good as the data it's trained on, and this pipeline ensures the data is robust, clean and consistent.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Data Loading and Validation](#data-loading)\n",
    "3. [Exploratory Data Analysis](#eda)\n",
    "4. [Feature Engineering Pipeline](#feature-engineering)\n",
    "5. [Feature Validation and Quality Checks](#validation)\n",
    "6. [Pipeline Serialization and Deployment](#deployment)\n",
    "7. [Monitoring and Logging](#monitoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import all necessary libraries for production feature engineering including:\n",
    "- Data manipulation and analysis\n",
    "- Feature engineering and preprocessing\n",
    "- Pipeline creation and serialization\n",
    "- Logging and monitoring\n",
    "- Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Scikit-learn for preprocessing and pipeline creation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler,\n",
    "    LabelEncoder, OneHotEncoder, OrdinalEncoder,\n",
    "    PolynomialFeatures, PowerTransformer\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Serialization and deployment\n",
    "import joblib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Logging/monitoring\n",
    "import logging\n",
    "import json\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "# Data Validation\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Config\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 77\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(f\"Setup completed at: {datetime.now()}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Validation\n",
    "\n",
    "Load data with comprehensive validation including:\n",
    "- Schema validation\n",
    "- Data quality checks\n",
    "- Missing value anlaysis\n",
    "- Data type validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to log file and console\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('feature_engineering.log'),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "# Logger object named after current module\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataValidator:\n",
    "    \"\"\"\n",
    "    Data validation class for production feature engineering.\n",
    "    Performs comprehensive data quality checks and schema validation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, expected_schema: Dict[str, str]):\n",
    "        self.expected_schema = expected_schema\n",
    "        self.validation_results = {}\n",
    "\n",
    "    def validate_schema(self, df: pd.DataFrame) -> bool:\n",
    "        \"\"\"Validate dataframe schema against expected schema.\"\"\"\n",
    "        logger.info(\"Starting schema validation\")\n",
    "\n",
    "        missing_cols = set(self.expected_schema.keys()) - set(df.columns)\n",
    "        extra_cols = set(df.columns) - set(self.expected_schema.keys())\n",
    "\n",
    "        if missing_cols:\n",
    "            logger.error(f\"Missing columns: {missing_cols}\")\n",
    "            return False\n",
    "        \n",
    "        if extra_cols:\n",
    "            logger.warning(f\"Unexpected columns found: {extra_cols}\")\n",
    "\n",
    "        # Validate data types, iterate over each real col and expected data type\n",
    "        type_mismatches = []\n",
    "        for col, expected_type in self.expected_schema.items():\n",
    "            if col in df.columns:\n",
    "                actual_type = str(df[col].dtype)\n",
    "                # lenient, as int might appear in int64\n",
    "                if expected_type not in actual_type and actual_type not in expected_type:\n",
    "                    type_mismatches.append((col, expected_type, actual_type))\n",
    "\n",
    "        if type_mismatches:\n",
    "            logger.warning(f\"Data type mismatches: {type_mismatches}\")\n",
    "\n",
    "        logger.info(\"Schema validation completed!\")\n",
    "        return True\n",
    "    \n",
    "    def validate_data_quality(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive data quality validation.\"\"\"\n",
    "        logger.info(\"Starting data quality validation\")\n",
    "\n",
    "        quality_report = {\n",
    "            'total_rows': len(df),\n",
    "            'total_columns': len(df.columns),\n",
    "            'missing_values': df.isnull().sum().to_dict(),\n",
    "            'missing_percentage': (df.isnull().sum() / len(df) * 100).to_dict(),\n",
    "            'duplicate_rows': df.duplicated().sum(),\n",
    "            'data_types': df.dtypes.astype(str).to_dict(),\n",
    "            'memory_usage': df.memory_usage(deep=True).sum() / 1024**2  # MB\n",
    "        }\n",
    "\n",
    "        # Check for columns with greater than 50% missing values\n",
    "        high_missing_cols = [\n",
    "            col for col, pct in quality_report['missing_precentage'].items()\n",
    "            if pct > 50\n",
    "        ]\n",
    "\n",
    "        if high_missing_cols:\n",
    "            logger.warning(f\"Columns with >50% missing values: {high_missing_cols}\")\n",
    "\n",
    "        # check for columns with 0 variance (np.number is superclass for all numeric types)\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        zero_variance_cols = [col for col in numeric_cols if df[col].var() == 0]\n",
    "\n",
    "        if zero_variance_cols:\n",
    "            logger.warning(f\"Columns with zero variance: {zero_variance_cols}\")\n",
    "        \n",
    "        quality_report['high_missing_columns'] = high_missing_cols\n",
    "        quality_report['zero_variance_columns'] = zero_variance_cols\n",
    "        \n",
    "        logger.info(\"Data quality validation completed!\")\n",
    "        return quality_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset or load one\n",
    "def create_sample_dataset():\n",
    "    \"\"\"Create a sample dataset for demonstration purposes.\"\"\"\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    n_samples = 10000\n",
    "    \n",
    "    data = {\n",
    "        'customer_id': range(1, n_samples + 1),\n",
    "        'age': np.random.randint(18, 80, n_samples),\n",
    "        'income': np.random.lognormal(10, 1, n_samples),\n",
    "        'credit_score': np.random.randint(300, 850, n_samples),\n",
    "        'account_balance': np.random.normal(5000, 2000, n_samples),\n",
    "        'num_products': np.random.poisson(2, n_samples),\n",
    "        'tenure_months': np.random.randint(1, 120, n_samples),\n",
    "        'is_active': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),\n",
    "        'geography': np.random.choice(['Urban', 'Suburban', 'Rural'], n_samples, p=[0.5, 0.3, 0.2]),\n",
    "        'gender': np.random.choice(['Male', 'Female'], n_samples, p=[0.52, 0.48]),\n",
    "        'has_credit_card': np.random.choice([0, 1], n_samples, p=[0.4, 0.6]),\n",
    "        'last_transaction_date': pd.date_range('2023-01-01', '2024-01-01', periods=n_samples),\n",
    "        'churn': None  # Target variable - will be generated based on features\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Generate target variable based on features using a realistic relationship\n",
    "    # We are adding these probabilities together\n",
    "    churn_prob = (\n",
    "        0.1 +                                            # Baseline risk\n",
    "        0.001 * (df['age'] - 40)**2 +                    # U-shaped age effect\n",
    "        -0.00001 * df['income'] +                        # Higher income = lower churn\n",
    "        -0.0002 * df['credit_score'] +                   # Higher credit score = lower churn\n",
    "        -0.01 * df['num_products'] +                     # More products = lower churn\n",
    "        -0.002 * df['tenure_months'] +                   # Longer tenure = lower churn\n",
    "        -0.1 * df['is_active'] +                         # Active users = lower churn\n",
    "        0.05 * (df['geography'] == 'Rural').astype(int)  # Rural = higher churn\n",
    "    )\n",
    "\n",
    "    # Ensure probabilities are between 0 and 1\n",
    "    churn_prob = np.clip(churn_prob, 0, 1)\n",
    "    df['churn'] = np.random.binomial(1, churn_prob, n_samples)\n",
    "    \n",
    "    # Introduce some missing values to simulate real-world data\n",
    "    df.loc[np.random.choice(df.index, size=500, replace=False), 'income'] = np.nan\n",
    "    df.loc[np.random.choice(df.index, size=300, replace=False), 'credit_score'] = np.nan\n",
    "    df.loc[np.random.choice(df.index, size=200, replace=False), 'account_balance'] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load and validate data\n",
    "logger.info(\"Loading dataset...\")\n",
    "df = create_sample_dataset()\n",
    "\n",
    "# Define the expected schema\n",
    "expected_schema = {\n",
    "    'customer_id': 'int64',\n",
    "    'age': 'int64',\n",
    "    'income': 'float64',\n",
    "    'credit_score': 'float64',\n",
    "    'account_balance': 'float64',\n",
    "    'num_products': 'int64',\n",
    "    'tenure_months': 'int64',\n",
    "    'is_active': 'int64',\n",
    "    'geography': 'object',\n",
    "    'gender': 'object',\n",
    "    'has_credit_card': 'int64',\n",
    "    'last_transaction_date': 'datetime64[ns]',\n",
    "    'churn': 'int64'\n",
    "}\n",
    "\n",
    "# Initialize validator and perform validation\n",
    "validator = DataValidator(expected_schema)\n",
    "is_valid_schema = validator.validate_schema(df)\n",
    "quality_report = validator.validate_data_quality(df)\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "print(json.dumps(quality_report, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Perform comprehensive EDA to understand data patterns and inform feature engineering decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Perform comprehensive exploratory data analysis (EDA).\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"Starting exploratory data analysis\")\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    # Describe gives descriptive stats, works only on numeric columns\n",
    "    # display makes the DF look like a table, part of Jupyter\n",
    "    print(\"\\nBasic Stats:\")\n",
    "    display(df.describe(include='all'))\n",
    "\n",
    "    print(\"\\nMissing Values Analysis:\")\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Missing Count': df.isnull().sum(),\n",
    "        'Missing Percentage': (df.isnull().sum() /len(df)) * 100\n",
    "    })\n",
    "    # missing_data['Missing Count'] > 0 Creates a boolean mask: Series of True/False values, one per row\n",
    "    # missing_data[boolean_mask] -> pandas does the filtering, only keeping where condition is true\n",
    "    missing_data = missing_data[missing_data['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "    # Assign it back to missing_data for clean reassignment\n",
    "    print(missing_data)\n",
    "\n",
    "    # Correlation analysis for numeric features (select only numeric column names)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        # .corr() computes the correlation matrix (pairwise correlations between all numeric columns)\n",
    "        correlation_matrix = df[numeric_cols].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "        plt.title('Feature Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Target variable distribution\n",
    "    if 'churn' in df.columns:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 3, 1) # 1 row, 3 columns of plots, this is the first plot\n",
    "        # plot the distribution of churn values, 0 vs 1\n",
    "        df['churn'].value_counts().plot(kind='bar')\n",
    "        plt.title('Target Variable Distribution')\n",
    "        plt.xlabel('Churn')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        # Age distribution by churn\n",
    "        plt.subplot(1, 3, 2)\n",
    "        for churn_val in df['churn'].unique():\n",
    "            subset = df[df['churn'] == churn_val]['age'].dropna()\n",
    "            plt.hist(subset, alpha=0.7, label=f'Churn = {churn_val}', bins=20)\n",
    "        plt.title('Age Distribution by Churn')\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Income distribution by churn\n",
    "        plt.subplot(1, 3, 3)\n",
    "        for churn_val in df['churn'].unique():\n",
    "            subset = df[df['churn'] == churn_val]['income'].dropna()\n",
    "            plt.hist(subset, alpha=0.7, label=f'Churn = {churn_val}', bins=20)\n",
    "        plt.title('Income Distribution by Churn')\n",
    "        plt.xlabel('Income')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.yscale('log')  # Log scale due to income distribution\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Categorical variable analysis\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        # create a row of subplots, 1 row, N columns (len(categorical_cols))\n",
    "        fig, axes = plt.subplots(1, len(categorical_cols), figsize=(15, 5))\n",
    "        if len(categorical_cols) == 1:\n",
    "            # if only 1 column, then axes will not be a list, so make it one\n",
    "            axes = [axes]\n",
    "            \n",
    "        # loop and plot each into its subplot\n",
    "        for i, col in enumerate(categorical_cols):\n",
    "            df[col].value_counts().plot(kind='bar', ax=axes[i])\n",
    "            axes[i].set_title(f'{col} Distribution')\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Perform EDA\n",
    "perform_eda(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Pipeline\n",
    "\n",
    "Create comprehensive feature engineering pipeline with custom transformers and production-ready components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class inheriting from BaseEstimator and TransformerMixin\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to extract date-based features.\n",
    "    Extracts multiple temporal features from datetime columns.\n",
    "    class will be able to get_params(), set_params().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, date_column: str, reference_date: Optional[datetime] = None):\n",
    "        self.date_column = date_column\n",
    "        self.reference_date = reference_date or datetime.now()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    # returning self ensures the transformer can participate in chained operations\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Extract comprehensive date features.\"\"\"\n",
    "        # Create a copy of the dataframe for manipulation\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        # make sure datetime type for the \n",
    "        if not pd.api.types.is_datetime64_any_dtype(X_copy[self.date_column]):\n",
    "            X_copy[self.date_column] = pd.to_datetime(X_copy[self.date_column])\n",
    "\n",
    "        # Extract temporal features by creating new columns using pd functions\n",
    "        X_copy[f'{self.date_column}_year'] = X_copy[self.date_column].dt.year\n",
    "        X_copy[f'{self.date_column}_month'] = X_copy[self.date_column].dt.month\n",
    "        X_copy[f'{self.date_column}_day'] = X_copy[self.date_column].dt.day\n",
    "        X_copy[f'{self.date_column}_dayofweek'] = X_copy[self.date_column].dt.dayofweek\n",
    "        X_copy[f'{self.date_column}_quarter'] = X_copy[self.date_column].dt.quarter\n",
    "        X_copy[f'{self.date_column}_is_weekend'] = (X_copy[self.date_column].dt.dayofweek >= 5).astype(int)\n",
    "        X_copy[f'{self.date_column}_is_month_end'] = X_copy[self.date_column].dt.is_month_end.astype(int)\n",
    "        X_copy[f'{self.date_column}_is_month_start'] = X_copy[self.date_column].dt.is_month_start.astype(int)\n",
    "\n",
    "        # Calculate days since reference date\n",
    "        X_copy[f'{self.date_column}_days_since_reference'] = (\n",
    "            self.reference_date - X_copy[self.date_column]\n",
    "        ).dt.days \n",
    "\n",
    "        # Drop original date column since we no longer need it\n",
    "        X_copy = X_copy.drop(columns=[self.date_column])\n",
    "\n",
    "        return X_copy\n",
    "    \n",
    "class BusinessFeatureCreator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to create business-specific features.\n",
    "    Creates domain-knowledge based features for better model performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Store statistical information for feature creation\n",
    "        self.income_percentiles = np.percentile(X['income'].dropna(), [25, 50, 75]) # Split into percentiles\n",
    "        self.credit_score_percentiles = np.percentile(X['credit_score'].dropna(), [25, 50, 75])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Creaste the business-specific features.\"\"\"\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        # Customer segmentation features with previously identified weights\n",
    "        X_copy['customer_value_score'] = (\n",
    "            0.3 * X_copy['account_balance'] + \n",
    "            0.3 * X_copy['income'] + \n",
    "            0.2 * X_copy['credit_score'] + \n",
    "            0.2 * X_copy['num_products'] * 1000\n",
    "        )\n",
    "\n",
    "        # Risk assessment features \n",
    "        # conditional assessment (where(condition, x, y)) and clipping\n",
    "        # if false, assign 0\n",
    "        X_copy['debt_to_income_ratio'] = np.where(\n",
    "            X_copy['income'] > 0,\n",
    "            -X_copy['account_balance'] / X_copy['income'],\n",
    "            0\n",
    "        )\n",
    "        # Values less than 0 become 0, and values greater than 10 become 10\n",
    "        X_copy['debt_to_income_ratio'] = np.clip(X_copy['debt_to_income_ratio'], 0, 10)\n",
    "\n",
    "        # Age-based features\n",
    "        # Cut converts continous age into categorical groups (one fewer for 0)\n",
    "        X_copy['age_group'] = pd.cut(\n",
    "            X_copy['age'],\n",
    "            bins=[0, 25, 35, 45, 55, 100],\n",
    "            labels=['young', 'young_adult', 'middle_age', 'mature', 'senior']\n",
    "        )\n",
    "\n",
    "        # Income-based features\n",
    "        X_copy['income_tier'] = pd.cut(\n",
    "            X_copy['income'], \n",
    "            bins=[-np.inf] + list(self.income_percentiles) + [np.inf],\n",
    "            labels=['low', 'medium_low', 'medium_high', 'high']\n",
    "        )\n",
    "        \n",
    "        # Credit score categories\n",
    "        X_copy['credit_category'] = pd.cut(\n",
    "            X_copy['credit_score'],\n",
    "            bins=[0, 580, 670, 740, 850],\n",
    "            labels=['poor', 'fair', 'good', 'excellent']\n",
    "        )\n",
    "        \n",
    "        # Interaction features\n",
    "        X_copy['products_per_tenure_month'] = X_copy['num_products'] / np.maximum(X_copy['tenure_months'], 1)\n",
    "        X_copy['balance_per_product'] = X_copy['account_balance'] / np.maximum(X_copy['num_products'], 1)\n",
    "        X_copy['age_tenure_interaction'] = X_copy['age'] * X_copy['tenure_months']\n",
    "        \n",
    "        # Boolean features\n",
    "        X_copy['is_high_value_customer'] = (\n",
    "            (X_copy['customer_value_score'] > X_copy['customer_value_score'].quantile(0.8)) & \n",
    "            (X_copy['num_products'] >= 3)\n",
    "        ).astype(int)\n",
    "        \n",
    "        X_copy['is_at_risk'] = (\n",
    "            (X_copy['debt_to_income_ratio'] > 0.5) | \n",
    "            (X_copy['account_balance'] < 0) |\n",
    "            (X_copy['credit_score'] < 600)\n",
    "        ).astype(int)\n",
    "        \n",
    "        return X_copy\n",
    "    \n",
    "class OutlierTreatment(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer for outlier detection and treatment.\n",
    "    Uses IQR method with configurable treatement strats.\n",
    "    Interquartile Range finds the values between Q1-Q3\n",
    "    \"\"\"\n",
    "\n",
    "    # Always run when new instance of class is created\n",
    "    # method and factor are hyperparameters of the transformer\n",
    "    # Factor is usually 1.5\n",
    "    def __init__(self, method='cap', factor=1.5):\n",
    "        \"\"\"\n",
    "        Initialize outlier treatment transformer.\n",
    "\n",
    "        Parameters:\n",
    "        method: 'cap', 'remove', or 'winsorize'\n",
    "        factor: IQR multiplier for outlier detection\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.factor = factor\n",
    "        self.outlier_bounds = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Calculate outlier bounds for numeric columns.\"\"\"\n",
    "        numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            # for each numeric column, the lower and upper bound are computed\n",
    "            lower_bound = Q1 - self.factor * IQR\n",
    "            upper_bound = Q3 + self.factor * IQR\n",
    "\n",
    "            # Produces a dictionary of dictionaries (age: lower: x, upper: u)\n",
    "            self.outlier_bounds[col] = {\n",
    "                'lower': lower_bound,\n",
    "                'upper': upper_bound\n",
    "            }\n",
    "\n",
    "            return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply outlier treatment.\"\"\"\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        for col, bounds in self.outlier_bounds.items():\n",
    "            if col in X_copy.columns:\n",
    "                if self.method == 'cap':\n",
    "                    X_copy[col] = np.clip(X_copy[col], bounds['lower'], bounds['upper'])\n",
    "                elif self.method == 'winsorize':\n",
    "                    X_copy[col] = X_copy[col].clip(lower=X_copy[col].quantile(0.05), \n",
    "                                                   upper=X_copy[col].quantile(0.95))\n",
    "        \n",
    "        return X_copy\n",
    "    \n",
    "def create_feature_engineering_pipeline():\n",
    "    \"\"\"\n",
    "    Create feature engineering pipeline.\n",
    "    Returns a scikit-learn pipeline ready for production usage.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the column groups\n",
    "    numeric_features = ['age', 'income', 'credit_score', 'account_balance', \n",
    "                       'num_products', 'tenure_months']\n",
    "    categorical_features = ['geography', 'gender']\n",
    "    binary_features = ['is_active', 'has_credit_card']\n",
    "\n",
    "    # Define the numeric processing pipeline\n",
    "    numeric_pipeline = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('outlier_treatment', OutlierTreatment(method='cap')),\n",
    "        ('scaler', RobustScaler()) # Robust to outliers\n",
    "    ])\n",
    "\n",
    "    # Define categorical pipeline\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Binary features pipeline with minimal preprocessing\n",
    "    binary_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "    ])\n",
    "\n",
    "    # Column transformer to apply different preprocessing to different column types\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_pipeline, numeric_features),\n",
    "            ('cat', categorical_pipeline, categorical_features),\n",
    "            ('bin', binary_pipeline, binary_features)\n",
    "        ],\n",
    "        remainder='passthrough' # keep other columns as is\n",
    "    )\n",
    "\n",
    "    # Complete feature pipeline\n",
    "    feature_pipeline = Pipeline([\n",
    "        ('date_features', DateFeatureExtractor('last_transaction_date')),\n",
    "        ('business_features', BusinessFeatureCreator()),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', SelectKBest(score_func=f_classif, k=20))\n",
    "    ])\n",
    "\n",
    "    return feature_pipeline\n",
    "\n",
    "# Now, create and display the pipeline\n",
    "feature_pipeline = create_feature_engineering_pipeline()\n",
    "print(\"Feature Engineering Pipeline Created:\")\n",
    "print(feature_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Validation and Quality Checks\n",
    "\n",
    "Implement comprehensive feature validation and quality monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureValidator:\n",
    "    \"\"\"\n",
    "    Comprehensive feature validation for production ML pipelines.\n",
    "    Monitors feature quality, distribution shifts, and data integrity.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, reference_stats: Optional[Dict] = None):\n",
    "        # If no reference stats (first run), empty dict\n",
    "        self.reference_stats = reference_stats or {}\n",
    "        self.validation_results = {}\n",
    "    \n",
    "    def calculate_feature_statistics(self, X: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate comprehensive feature statistics.\"\"\"\n",
    "        # Create the stats dict\n",
    "        stats = {\n",
    "            'shape': X.shape,\n",
    "            'missing_values': X.isnull().sum().to_dict(),\n",
    "            'data_types': X.dtypes.astype(str).to_dict(),\n",
    "            'numeric_stats': {},\n",
    "            'categorical_stats': {}\n",
    "        }\n",
    "        \n",
    "        # Numeric feature statistics for numeric columns only\n",
    "        numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            col_stats = {\n",
    "                'mean': X[col].mean(),\n",
    "                'std': X[col].std(),\n",
    "                'min': X[col].min(),\n",
    "                'max': X[col].max(),\n",
    "                'q25': X[col].quantile(0.25),\n",
    "                'q50': X[col].quantile(0.50),\n",
    "                'q75': X[col].quantile(0.75),\n",
    "                'skewness': X[col].skew(), # Skew 0 is perfectly symmetric\n",
    "                'kurtosis': X[col].kurtosis(), # \"tailedness\"/concentration of outliers\n",
    "                'zero_count': (X[col] == 0).sum(),\n",
    "                'unique_count': X[col].nunique()\n",
    "            }\n",
    "            # Add numeric_stats to the dict\n",
    "            stats['numeric_stats'][col] = col_stats\n",
    "        \n",
    "        # Categorical feature statistics\n",
    "        # iloc[0] grabs the first mode (in case of ties)\n",
    "        categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "        for col in categorical_cols:\n",
    "            col_stats = {\n",
    "                'unique_count': X[col].nunique(),\n",
    "                'mode': X[col].mode().iloc[0] if len(X[col].mode()) > 0 else None,\n",
    "                'value_counts': X[col].value_counts().to_dict()\n",
    "            }\n",
    "            # Categorical stats key will be added, and each category has its own entry\n",
    "            # with unique count, mode, and value counts dict\n",
    "            stats['categorical_stats'][col] = col_stats\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def detect_distribution_shift(self, current_stats: Dict, reference_stats: Dict, \n",
    "                                threshold: float = 0.1) -> Dict[str, Any]:\n",
    "        \"\"\"Detect distribution shifts in features.\"\"\"\n",
    "        shifts = {\n",
    "            'numeric_shifts': {},\n",
    "            'categorical_shifts': {},\n",
    "            'alerts': []\n",
    "        }\n",
    "        \n",
    "        # Check numeric feature shifts\n",
    "        for col in current_stats['numeric_stats']:\n",
    "            if col in reference_stats['numeric_stats']:\n",
    "                current = current_stats['numeric_stats'][col]\n",
    "                reference = reference_stats['numeric_stats'][col]\n",
    "                \n",
    "                # Calculate relative changes\n",
    "                mean_shift = abs(current['mean'] - reference['mean']) / abs(reference['mean'])\n",
    "                std_shift = abs(current['std'] - reference['std']) / abs(reference['std']) if reference['std'] > 0 else 0\n",
    "                \n",
    "                shifts['numeric_shifts'][col] = {\n",
    "                    'mean_shift': mean_shift,\n",
    "                    'std_shift': std_shift,\n",
    "                    'alert': mean_shift > threshold or std_shift > threshold\n",
    "                }\n",
    "                \n",
    "                if shifts['numeric_shifts'][col]['alert']:\n",
    "                    shifts['alerts'].append(f\"Distribution shift detected in {col}\")\n",
    "        \n",
    "        # Check categorical feature shifts using chi-square test\n",
    "        for col in current_stats['categorical_stats']:\n",
    "            if col in reference_stats['categorical_stats']:\n",
    "                current_counts = current_stats['categorical_stats'][col]['value_counts']\n",
    "                reference_counts = reference_stats['categorical_stats'][col]['value_counts']\n",
    "                \n",
    "                # Align categories\n",
    "                all_categories = set(current_counts.keys()) | set(reference_counts.keys())\n",
    "                current_aligned = [current_counts.get(cat, 0) for cat in all_categories]\n",
    "                reference_aligned = [reference_counts.get(cat, 0) for cat in all_categories]\n",
    "                \n",
    "                # Perform chi-square test if sufficient data\n",
    "                if sum(current_aligned) > 0 and sum(reference_aligned) > 0:\n",
    "                    try:\n",
    "                        chi2, p_value = stats.chisquare(current_aligned, reference_aligned)\n",
    "                        shifts['categorical_shifts'][col] = {\n",
    "                            'chi2_statistic': chi2,\n",
    "                            'p_value': p_value,\n",
    "                            'alert': p_value < 0.05\n",
    "                        }\n",
    "                        \n",
    "                        if p_value < 0.05:\n",
    "                            shifts['alerts'].append(f\"Categorical distribution shift detected in {col}\")\n",
    "                    except:\n",
    "                        shifts['categorical_shifts'][col] = {'error': 'Could not perform test'}\n",
    "        \n",
    "        return shifts\n",
    "    \n",
    "    def validate_feature_quality(self, X: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Perform comprehensive feature quality validation.\"\"\"\n",
    "        quality_issues = {\n",
    "            'high_missing_features': [],\n",
    "            'zero_variance_features': [],\n",
    "            'high_cardinality_features': [],\n",
    "            'potential_data_leakage': [],\n",
    "            'correlation_issues': []\n",
    "        }\n",
    "        \n",
    "        # Check for high missing value percentage\n",
    "        missing_pct = (X.isnull().sum() / len(X)) * 100\n",
    "        quality_issues['high_missing_features'] = missing_pct[missing_pct > 50].index.tolist()\n",
    "        \n",
    "        # Check for zero variance features\n",
    "        numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            if X[col].var() == 0:\n",
    "                quality_issues['zero_variance_features'].append(col)\n",
    "        \n",
    "        # Check for high cardinality categorical features\n",
    "        categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "        for col in categorical_cols:\n",
    "            if X[col].nunique() > 100:  # Arbitrary threshold\n",
    "                quality_issues['high_cardinality_features'].append(col)\n",
    "        \n",
    "        # Check for highly correlated features\n",
    "        if len(numeric_cols) > 1:\n",
    "            corr_matrix = X[numeric_cols].corr().abs()\n",
    "            high_corr_pairs = []\n",
    "            for i in range(len(corr_matrix.columns)):\n",
    "                for j in range(i+1, len(corr_matrix.columns)):\n",
    "                    if corr_matrix.iloc[i, j] > 0.95:\n",
    "                        high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j]))\n",
    "            quality_issues['correlation_issues'] = high_corr_pairs\n",
    "        \n",
    "        return quality_issues\n",
    "\n",
    "# Apply feature engineering pipeline to our data\n",
    "logger.info(\"Applying feature engineering pipeline...\")\n",
    "\n",
    "# Split data before feature engineering to prevent data leakage\n",
    "X = df.drop(['customer_id', 'churn'], axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_transformed = feature_pipeline.fit_transform(X_train, y_train)\n",
    "X_test_transformed = feature_pipeline.transform(X_test)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "feature_names = feature_pipeline.named_steps['feature_selection'].get_feature_names_out()\n",
    "X_train_df = pd.DataFrame(X_train_transformed, columns=feature_names, index=X_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_transformed, columns=feature_names, index=X_test.index)\n",
    "\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "print(f\"Engineered features: {X_train_df.shape[1]}\")\n",
    "print(f\"Training set shape: {X_train_df.shape}\")\n",
    "print(f\"Test set shape: {X_test_df.shape}\")\n",
    "\n",
    "# Validate transformed features\n",
    "validator = FeatureValidator()\n",
    "\n",
    "# Calculate statistics for training data (reference)\n",
    "train_stats = validator.calculate_feature_statistics(X_train_df)\n",
    "print(\"\\nTraining Data Statistics:\")\n",
    "print(f\"Missing values: {sum(train_stats['missing_values'].values())}\")\n",
    "print(f\"Numeric features: {len(train_stats['numeric_stats'])}\")\n",
    "print(f\"Categorical features: {len(train_stats['categorical_stats'])}\")\n",
    "\n",
    "# Calculate statistics for test data\n",
    "test_stats = validator.calculate_feature_statistics(X_test_df)\n",
    "\n",
    "# Check for distribution shifts between train and test\n",
    "shifts = validator.detect_distribution_shift(test_stats, train_stats, threshold=0.1)\n",
    "print(f\"\\nDistribution Shift Analysis:\")\n",
    "print(f\"Numeric shifts detected: {len([k for k, v in shifts['numeric_shifts'].items() if v['alert']])}\")\n",
    "print(f\"Categorical shifts detected: {len([k for k, v in shifts['categorical_shifts'].items() if v['alert']])}\")\n",
    "\n",
    "if shifts['alerts']:\n",
    "    print(\"Alerts:\")\n",
    "    for alert in shifts['alerts']:\n",
    "        print(f\"  - {alert}\")\n",
    "\n",
    "# Validate feature quality\n",
    "quality_issues = validator.validate_feature_quality(X_train_df)\n",
    "print(f\"\\nFeature Quality Issues:\")\n",
    "for issue_type, issues in quality_issues.items():\n",
    "    if issues:\n",
    "        print(f\"  {issue_type}: {issues}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline Serialization and Deployment\n",
    "\n",
    "Save the feature engineering pipeline and create deployment-ready artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePipelineManager:\n",
    "    \"\"\"\n",
    "    Manager class for feature pipeline serialization, versioning, and deployment.\n",
    "    Handles saving/loading pipelines and maintaining metadata.\n",
    "    Pipelines json and joblib will be in feature_pipelines/pipeline_name/v1..\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pipeline_dir: str = \"feature_pipelines\"):\n",
    "        self.pipeline_dir = Path(pipeline_dir)\n",
    "        self.pipeline_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def save_pipeline(self, pipeline, pipeline_name: str, version: str = \"v1\",\n",
    "                      metadata: Optional[Dict] = None):\n",
    "        \"\"\"Save feature pipeline with versioning and metadata.\"\"\"\n",
    "    \n",
    "        # Create version dir\n",
    "        version_dir = self.pipeline_dir / pipeline_name / version\n",
    "        version_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        pipeline_path = version_dir / \"pipeline.joblib\"\n",
    "        joblib.dump(pipeline, pipeline_path)\n",
    "\n",
    "        metadata = metadata or {}\n",
    "        metadata.update({\n",
    "            'pipeline_name': pipeline_name,\n",
    "            'version': version,\n",
    "            'created_at': datetime.now().isoformat(),\n",
    "            'pipeline_type': str(type(pipeline)),\n",
    "            'sklearn_version': joblib.__version__\n",
    "        })\n",
    "\n",
    "        metadata_path = version_dir / \"metadata.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"Pipeline saved: {pipeline_path}\")\n",
    "        logger.info(f\"Metadata saved: {metadata_path}\")\n",
    "        \n",
    "        return pipeline_path, metadata_path\n",
    "    \n",
    "    def load_pipeline(self, pipeline_name: str, version: str = \"latest\"):\n",
    "        \"\"\"Load feature pipeline with version control.\"\"\"\n",
    "        \n",
    "        pipeline_base = self.pipeline_dir / pipeline_name\n",
    "        \n",
    "        if version == \"latest\":\n",
    "            # Find the latest version\n",
    "            version_dirs = [d for d in pipeline_base.iterdir() if d.is_dir()]\n",
    "            if not version_dirs:\n",
    "                raise FileNotFoundError(f\"No versions found for pipeline {pipeline_name}\")\n",
    "            \n",
    "            # Sort versions (assuming semantic versioning)\n",
    "            version_dirs.sort(key=lambda x: x.name)\n",
    "            version_dir = version_dirs[-1]\n",
    "        else:\n",
    "            version_dir = pipeline_base / version\n",
    "            \n",
    "        if not version_dir.exists():\n",
    "            raise FileNotFoundError(f\"Version {version} not found for pipeline {pipeline_name}\")\n",
    "        \n",
    "        # Load pipeline\n",
    "        pipeline_path = version_dir / \"pipeline.joblib\"\n",
    "        pipeline = joblib.load(pipeline_path)\n",
    "\n",
    "        # Load metadata\n",
    "        metadata_path = version_dir / \"metadata.json\"\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        logger.info(f\"Pipeline loaded: {pipeline_path}\")\n",
    "        return pipeline, metadata\n",
    "        \n",
    "    def list_pipelines(self):\n",
    "        \"\"\"List all available pipelines and versions.\"\"\"\n",
    "        pipelines = {}\n",
    "        \n",
    "        for pipeline_dir in self.pipeline_dir.iterdir():\n",
    "            if pipeline_dir.is_dir():\n",
    "                versions = []\n",
    "                for version_dir in pipeline_dir.iterdir():\n",
    "                    if version_dir.is_dir() and (version_dir / \"pipeline.joblib\").exists():\n",
    "                        metadata_path = version_dir / \"metadata.json\"\n",
    "                        if metadata_path.exists():\n",
    "                            with open(metadata_path, 'r') as f:\n",
    "                                metadata = json.load(f)\n",
    "                            versions.append({\n",
    "                                'version': version_dir.name,\n",
    "                                'created_at': metadata.get('created_at'),\n",
    "                                'metadata': metadata\n",
    "                            })\n",
    "                \n",
    "                if versions:\n",
    "                    pipelines[pipeline_dir.name] = sorted(versions, key=lambda x: x['created_at'])\n",
    "        \n",
    "        return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deployment_artifacts():\n",
    "    \"\"\"Create all necessary artifacts for deployment.\"\"\"\n",
    "    \n",
    "    # Initialize pipeline manager\n",
    "    pipeline_manager = FeaturePipelineManager()\n",
    "    \n",
    "    # Pipeline metadata\n",
    "    pipeline_metadata = {\n",
    "        'description': 'Customer churn prediction feature engineering pipeline',\n",
    "        'features': {\n",
    "            'input_features': list(X_train.columns),\n",
    "            'output_features': list(X_train_df.columns),\n",
    "            'feature_count': X_train_df.shape[1]\n",
    "        },\n",
    "        'preprocessing_steps': [\n",
    "            'Date feature extraction',\n",
    "            'Business feature creation',\n",
    "            'Missing value imputation',\n",
    "            'Outlier treatment',\n",
    "            'Scaling and encoding',\n",
    "            'Feature selection'\n",
    "        ],\n",
    "        'validation_results': {\n",
    "            'train_shape': X_train_df.shape,\n",
    "            'test_shape': X_test_df.shape,\n",
    "            'quality_issues': quality_issues\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save pipeline using pipeline manager\n",
    "    pipeline_path, metadata_path = pipeline_manager.save_pipeline(\n",
    "        pipeline=feature_pipeline,\n",
    "        pipeline_name=\"customer_churn_features\",\n",
    "        version=\"v1.0\",\n",
    "        metadata=pipeline_metadata\n",
    "    )\n",
    "    \n",
    "    # Create feature schema for API validation using X_train\n",
    "    feature_schema = {\n",
    "        'input_schema': {\n",
    "            col: {\n",
    "                'type': str(X_train[col].dtype),\n",
    "                'nullable': X_train[col].isnull().any(),\n",
    "                'min_value': X_train[col].min() if pd.api.types.is_numeric_dtype(X_train[col]) else None,\n",
    "                'max_value': X_train[col].max() if pd.api.types.is_numeric_dtype(X_train[col]) else None,\n",
    "                'categories': X_train[col].unique().tolist() if X_train[col].dtype == 'object' else None\n",
    "            }\n",
    "            for col in X_train.columns\n",
    "        },\n",
    "        'output_schema': {\n",
    "            col: {\n",
    "                'type': str(X_train_df[col].dtype),\n",
    "                'nullable': False\n",
    "            }\n",
    "            for col in X_train_df.columns\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save feature schema\n",
    "    schema_path = pipeline_path.parent / \"feature_schema.json\"\n",
    "    with open(schema_path, 'w') as f:\n",
    "        json.dump(feature_schema, f, indent=2, default=str)\n",
    "    \n",
    "    # Create sample prediction function\n",
    "    prediction_code = '''\n",
    "def predict_with_features(raw_data, pipeline_path):\n",
    "    \"\"\"\n",
    "    Production prediction function with feature engineering.\n",
    "    \n",
    "    Args:\n",
    "        raw_data (dict or pd.DataFrame): Raw input data\n",
    "        pipeline_path (str): Path to saved feature pipeline\n",
    "        \n",
    "    Returns:\n",
    "        dict: Predictions with engineered features\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load pipeline\n",
    "    feature_pipeline = joblib.load(pipeline_path)\n",
    "    \n",
    "    # Convert to DataFrame if needed\n",
    "    if isinstance(raw_data, dict):\n",
    "        df = pd.DataFrame([raw_data])\n",
    "    else:\n",
    "        df = raw_data.copy()\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    features = feature_pipeline.transform(df)\n",
    "    \n",
    "    # Here you would load your trained model and make predictions\n",
    "    # predictions = model.predict(features)\n",
    "    \n",
    "    return {\n",
    "        'features': features.tolist(),\n",
    "        'feature_names': feature_pipeline.named_steps['feature_selection'].get_feature_names_out().tolist()\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# result = predict_with_features(\n",
    "#     raw_data={'age': 35, 'income': 50000, ...},\n",
    "#     pipeline_path='feature_pipelines/customer_churn_features/v1.0/pipeline.joblib'\n",
    "# )\n",
    "'''\n",
    "    \n",
    "    # Save prediction function\n",
    "    function_path = pipeline_path.parent / \"prediction_function.py\"\n",
    "    with open(function_path, 'w') as f:\n",
    "        f.write(prediction_code)\n",
    "    \n",
    "    return {\n",
    "        'pipeline_path': pipeline_path,\n",
    "        'metadata_path': metadata_path,\n",
    "        'schema_path': schema_path,\n",
    "        'function_path': function_path\n",
    "    }\n",
    "\n",
    "# Create deployment artifacts\n",
    "deployment_artifacts = create_deployment_artifacts()\n",
    "\n",
    "print(\"Deployment Artifacts Created:\")\n",
    "for artifact_type, path in deployment_artifacts.items():\n",
    "    print(f\"  {artifact_type}: {path}\")\n",
    "\n",
    "# List all available pipelines\n",
    "pipeline_manager = FeaturePipelineManager()\n",
    "available_pipelines = pipeline_manager.list_pipelines()\n",
    "\n",
    "print(\"\\nAvailable Pipelines:\")\n",
    "for pipeline_name, versions in available_pipelines.items():\n",
    "    print(f\"  {pipeline_name}:\")\n",
    "    for version_info in versions:\n",
    "        print(f\"    - {version_info['version']} (created: {version_info['created_at']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitoring and Logging\n",
    "\n",
    "Implement comprehensive monitoring for production feature pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMonitor:\n",
    "    \"\"\"\n",
    "    Production monitoring class for feature engineering pipelines created in this notebook.\n",
    "    Tracks feature quality, performance, and data drift over time.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up the directory monitoring_logs\n",
    "    def __init__(self, log_dir: str = \"monitoring_logs\"):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.log_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Setup monitoring logger\n",
    "        self.monitor_logger = logging.getLogger('feature_monitor')\n",
    "        handler = logging.FileHandler(self.log_dir / 'feature_monitoring.log')\n",
    "        handler.setFormatter(logging.Formatter(\n",
    "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "        ))\n",
    "        self.monitor_logger.addHandler(handler)\n",
    "        self.monitor_logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Record metrics each time the pipeline runs\n",
    "    def log_pipeline_execution(self, pipeline_name: str, input_shape: Tuple, \n",
    "                              output_shape: Tuple, execution_time: float, \n",
    "                              quality_metrics: Dict):\n",
    "        \"\"\"Log pipeline execution metrics.\"\"\"\n",
    "        \n",
    "        log_entry = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'pipeline_name': pipeline_name,\n",
    "            'input_shape': input_shape,\n",
    "            'output_shape': output_shape,\n",
    "            'execution_time_seconds': execution_time,\n",
    "            'quality_metrics': quality_metrics\n",
    "        }\n",
    "        \n",
    "        # Add the log entry created to the logger\n",
    "        self.monitor_logger.info(f\"Pipeline execution: {json.dumps(log_entry)}\")\n",
    "        \n",
    "        # Save detailed metrics\n",
    "        metrics_file = self.log_dir / f\"metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(metrics_file, 'w') as f:\n",
    "            json.dump(log_entry, f, indent=2)\n",
    "        \n",
    "        return log_entry\n",
    "    \n",
    "    def monitor_data_drift(self, current_data: pd.DataFrame, \n",
    "                          reference_data: pd.DataFrame, \n",
    "                          threshold: float = 0.05) -> Dict:\n",
    "        \"\"\"\n",
    "        Monitor for data drift using statistical tests.\n",
    "        Threshold or p value is 5%\n",
    "        \"\"\"\n",
    "        \n",
    "        drift_results = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'drift_detected': False,\n",
    "            'drifted_features': [],\n",
    "            'drift_scores': {}\n",
    "        }\n",
    "        \n",
    "        numeric_cols = current_data.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in reference_data.columns:\n",
    "                # Kolmogorov-Smirnov test for distribution comparison\n",
    "                try:\n",
    "                    ks_statistic, p_value = stats.ks_2samp(\n",
    "                        reference_data[col].dropna(), \n",
    "                        current_data[col].dropna()\n",
    "                    )\n",
    "                    \n",
    "                    drift_results['drift_scores'][col] = {\n",
    "                        'ks_statistic': ks_statistic,\n",
    "                        'p_value': p_value,\n",
    "                        'drift_detected': p_value < threshold\n",
    "                    }\n",
    "                    \n",
    "                    if p_value < threshold:\n",
    "                        drift_results['drifted_features'].append(col)\n",
    "                        drift_results['drift_detected'] = True\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    self.monitor_logger.error(f\"Error testing drift for {col}: {str(e)}\")\n",
    "        \n",
    "        # Log drift results\n",
    "        if drift_results['drift_detected']:\n",
    "            self.monitor_logger.warning(f\"Data drift detected: {json.dumps(drift_results)}\")\n",
    "        else:\n",
    "            self.monitor_logger.info(\"No significant data drift detected\")\n",
    "        \n",
    "        return drift_results\n",
    "    \n",
    "    def generate_monitoring_report(self, days_back: int = 7) -> Dict:\n",
    "        \"\"\"Generate comprehensive monitoring report.\"\"\"\n",
    "        \n",
    "        # Read recent log entries\n",
    "        log_file = self.log_dir / 'feature_monitoring.log'\n",
    "        \n",
    "        report = {\n",
    "            'report_period': f\"Last {days_back} days\",\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'pipeline_executions': 0,\n",
    "            'average_execution_time': 0,\n",
    "            'error_count': 0,\n",
    "            'drift_alerts': 0\n",
    "        }\n",
    "        \n",
    "        if log_file.exists():\n",
    "            with open(log_file, 'r') as f:\n",
    "                logs = f.readlines()\n",
    "            \n",
    "            # Parse recent logs\n",
    "            cutoff_date = datetime.now() - timedelta(days=days_back)\n",
    "            execution_times = []\n",
    "            \n",
    "            for log_line in logs:\n",
    "                try:\n",
    "                    if 'Pipeline execution:' in log_line:\n",
    "                        # Extract timestamp and check if within period\n",
    "                        timestamp_str = log_line.split(' - ')[0]\n",
    "                        timestamp = datetime.fromisoformat(timestamp_str)\n",
    "                        \n",
    "                        if timestamp > cutoff_date:\n",
    "                            report['pipeline_executions'] += 1\n",
    "                            \n",
    "                            # Extract execution time from JSON\n",
    "                            json_part = log_line.split('Pipeline execution: ')[1]\n",
    "                            execution_data = json.loads(json_part)\n",
    "                            execution_times.append(execution_data.get('execution_time_seconds', 0))\n",
    "                    \n",
    "                    elif 'ERROR' in log_line and cutoff_date < datetime.fromisoformat(log_line.split(' - ')[0]):\n",
    "                        report['error_count'] += 1\n",
    "                    \n",
    "                    elif 'Data drift detected' in log_line and cutoff_date < datetime.fromisoformat(log_line.split(' - ')[0]):\n",
    "                        report['drift_alerts'] += 1\n",
    "                        \n",
    "                except Exception:\n",
    "                    continue  # Skip malformed log lines\n",
    "            \n",
    "            if execution_times:\n",
    "                report['average_execution_time'] = sum(execution_times) / len(execution_times)\n",
    "        \n",
    "        return report\n",
    "\n",
    "def demonstrate_monitoring():\n",
    "    \"\"\"Demonstrate the monitoring system with our pipeline.\"\"\"\n",
    "    \n",
    "    # Initialize monitor\n",
    "    monitor = FeatureMonitor()\n",
    "    \n",
    "    # Simulate pipeline execution monitoring\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Mock pipeline execution (in real scenario, this would be actual pipeline run)\n",
    "    execution_time = 2.5  # seconds\n",
    "    \n",
    "    # Calculate quality metrics\n",
    "    quality_metrics = {\n",
    "        'missing_values_count': int(X_train_df.isnull().sum().sum()),\n",
    "        'feature_count': X_train_df.shape[1],\n",
    "        'outlier_count': 0,  # Would be calculated by outlier detection\n",
    "        'data_quality_score': 0.95  # Overall quality score\n",
    "    }\n",
    "    \n",
    "    # Log pipeline execution\n",
    "    log_entry = monitor.log_pipeline_execution(\n",
    "        pipeline_name=\"customer_churn_features_v1\",\n",
    "        input_shape=X_train.shape,\n",
    "        output_shape=X_train_df.shape,\n",
    "        execution_time=execution_time,\n",
    "        quality_metrics=quality_metrics\n",
    "    )\n",
    "    \n",
    "    print(\"Pipeline Execution Logged:\")\n",
    "    print(json.dumps(log_entry, indent=2))\n",
    "    \n",
    "    # Monitor for data drift between train and test sets\n",
    "    drift_results = monitor.monitor_data_drift(X_test_df, X_train_df, threshold=0.05)\n",
    "    \n",
    "    print(\"\\nDrift Monitoring Results:\")\n",
    "    print(f\"Drift detected: {drift_results['drift_detected']}\")\n",
    "    print(f\"Drifted features: {drift_results['drifted_features']}\")\n",
    "    \n",
    "    if drift_results['drift_detected']:\n",
    "        print(\"Drift scores for affected features:\")\n",
    "        for feature in drift_results['drifted_features']:\n",
    "            scores = drift_results['drift_scores'][feature]\n",
    "            print(f\"  {feature}: KS statistic = {scores['ks_statistic']:.4f}, p-value = {scores['p_value']:.6f}\")\n",
    "    \n",
    "    # Generate monitoring report\n",
    "    report = monitor.generate_monitoring_report(days_back=1)\n",
    "    \n",
    "    print(\"\\nMonitoring Report:\")\n",
    "    print(json.dumps(report, indent=2))\n",
    "    \n",
    "    return monitor, log_entry, drift_results, report\n",
    "\n",
    "# Run monitoring demonstration\n",
    "monitor, log_entry, drift_results, report = demonstrate_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training with Engineered Features\n",
    "\n",
    "Demonstrate how the engineered features improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models():\n",
    "    \"\"\"\n",
    "    Train models with and without feature engineering to demonstrate improvement.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Model with original features (minimal preprocessing)\n",
    "    original_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    # Model with engineered features\n",
    "    engineered_pipeline = Pipeline([\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "    \n",
    "    # Prepare original features (numeric only for simplicity)\n",
    "    X_train_original = X_train.select_dtypes(include=[np.number])\n",
    "    X_test_original = X_test.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Train model with original features\n",
    "    print(\"Training model with original features...\")\n",
    "    original_pipeline.fit(X_train_original, y_train)\n",
    "    y_pred_original = original_pipeline.predict(X_test_original)\n",
    "    \n",
    "    # Train model with engineered features\n",
    "    print(\"Training model with engineered features...\")\n",
    "    engineered_pipeline.fit(X_train_df, y_train)\n",
    "    y_pred_engineered = engineered_pipeline.predict(X_test_df)\n",
    "    \n",
    "    # Compare performance\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    \n",
    "    def calculate_metrics(y_true, y_pred, y_prob=None):\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred),\n",
    "            'recall': recall_score(y_true, y_pred),\n",
    "            'f1_score': f1_score(y_true, y_pred)\n",
    "        }\n",
    "        if y_prob is not None:\n",
    "            metrics['roc_auc'] = roc_auc_score(y_true, y_prob)\n",
    "        return metrics\n",
    "    \n",
    "    # y_test is the true labels\n",
    "    # y_pred is the models predicted labels, and y_prob is the predicted probability\n",
    "    \n",
    "    # Calculate probabilities for ROC AUC\n",
    "    y_prob_original = original_pipeline.predict_proba(X_test_original)[:, 1]\n",
    "    y_prob_engineered = engineered_pipeline.predict_proba(X_test_df)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    original_metrics = calculate_metrics(y_test, y_pred_original, y_prob_original)\n",
    "    engineered_metrics = calculate_metrics(y_test, y_pred_engineered, y_prob_engineered)\n",
    "    \n",
    "    # Display results with border\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"{'Metric':<15} {'Original':<12} {'Engineered':<12} {'Improvement':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for metric in original_metrics:\n",
    "        original_val = original_metrics[metric]\n",
    "        engineered_val = engineered_metrics[metric]\n",
    "        improvement = ((engineered_val - original_val) / original_val) * 100\n",
    "        \n",
    "        print(f\"{metric:<15} {original_val:<12.4f} {engineered_val:<12.4f} {improvement:>+8.2f}%\")\n",
    "    \n",
    "    # Feature importance analysis\n",
    "    feature_importance = engineered_pipeline.named_steps['classifier'].feature_importances_\n",
    "    feature_names = X_train_df.columns\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = importance_df.head(15)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 15 Feature Importances (Engineered Features)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'original_metrics': original_metrics,\n",
    "        'engineered_metrics': engineered_metrics,\n",
    "        'feature_importance': importance_df,\n",
    "        'models': {\n",
    "            'original': original_pipeline,\n",
    "            'engineered': engineered_pipeline\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Train and evaluate models\n",
    "results = train_and_evaluate_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Best Practices\n",
    "PRODUCTION FEATURE ENGINEERING BEST PRACTICES DEMONSTRATED:\n",
    "\n",
    "1. DATA VALIDATION\n",
    "    Schema validation with expected data types\n",
    "    Data quality checks and missing value analysis\n",
    "    Outlier detection and treatment\n",
    "\n",
    "2. FEATURE ENGINEERING PIPELINE\n",
    "    Custom transformers for domain-specific features\n",
    "    Proper handling of different data types (numeric, categorical, datetime)\n",
    "    Feature scaling and normalization\n",
    "    Feature selection for dimensionality reduction\n",
    "\n",
    "3. PRODUCTION READINESS\n",
    "    Pipeline serialization and versioning\n",
    "    Comprehensive logging and monitoring\n",
    "    Data drift detection\n",
    "    Feature validation and quality checks\n",
    "\n",
    "4. MLOPS INTEGRATION\n",
    "    Reproducible pipeline with version control\n",
    "    Monitoring and alerting capabilities\n",
    "    Deployment artifacts and schemas\n",
    "    Performance tracking and comparison\n",
    "\n",
    "5. MODEL IMPROVEMENT\n",
    "    Significant performance gains through feature engineering\n",
    "    Feature importance analysis\n",
    "    Business domain knowledge incorporation\n",
    "\n",
    "KEY TAKEAWAYS:\n",
    "- Feature engineering can significantly improve model performance\n",
    "- Production pipelines need comprehensive validation and monitoring\n",
    "- Proper versioning and serialization enable reliable deployments\n",
    "- Domain knowledge is crucial for creating meaningful features\n",
    "- Continuous monitoring helps detect data drift and quality issues\n",
    "\n",
    "NEXT STEPS FOR PRODUCTION:\n",
    "1. Integrate with your ML platform (MLflow, Kubeflow, etc.)\n",
    "2. Set up automated retraining based on drift detection\n",
    "3. Implement A/B testing for feature engineering changes\n",
    "4. Add more sophisticated feature validation rules\n",
    "5. Create automated feature engineering based on data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final logging\n",
    "logger.info(\"Feature engineering pipeline demonstration completed successfully\")\n",
    "logger.info(f\"Final model performance improvement: {((results['engineered_metrics']['f1_score'] - results['original_metrics']['f1_score']) / results['original_metrics']['f1_score']) * 100:.2f}% F1-score improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Sections:\n",
    "\n",
    "1. **Setup and Imports** - All necessary libraries with proper configuration\n",
    "2. **Data Loading and Validation** - Schema validation, data quality checks, and synthetic dataset creation\n",
    "3. **Exploratory Data Analysis** - Comprehensive EDA with visualizations and statistical analysis\n",
    "4. **Feature Engineering Pipeline** - Custom transformers, preprocessing pipelines, and feature creation\n",
    "5. **Feature Validation and Quality Checks** - Distribution shift detection and quality monitoring\n",
    "6. **Pipeline Serialization and Deployment** - Versioning, metadata management, and deployment artifacts\n",
    "7. **Monitoring and Logging** - Production monitoring with drift detection and reporting\n",
    "8. **Model Training and Evaluation** - Performance comparison showing feature engineering benefits\n",
    "9. **Summary and Best Practices** - Key takeaways and production guidelines\n",
    "\n",
    "## Key Features Demonstrated:\n",
    "\n",
    "- **Custom Transformers**: DateFeatureExtractor, BusinessFeatureCreator, OutlierTreatment.\n",
    "- **Production Pipeline**: Complete scikit-learn pipeline with proper preprocessing.\n",
    "- **Validation Framework**: Comprehensive data validation and quality checks.\n",
    "- **Deployment Ready**: Serialization, versioning, and schema management.\n",
    "- **Monitoring System**: Data drift detection and performance tracking.\n",
    "- **Performance Analysis**: Clear demonstration of feature engineering benefits."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
