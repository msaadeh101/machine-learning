{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fine tuning the DistilBERT model on emotion dataset from huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Conda to install the below libraries in the environment. This environment uses Python 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load a Hugging Face Dataset (small subset for quick training) ---\n",
    "print(\"Loading dataset...\")\n",
    "# Small subset of the 'emotion' dataset for quick training\n",
    "# For a faster run, you can even take a smaller slice or a simpler dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "# designed for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a small sample to ensure quick training\n",
    "# You can adjust the size of the samples\n",
    "# Train dataset - where the model learns patterns\n",
    "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000)) # 1000 examples\n",
    "# Validate dataset - Tune hyperparameters (learning rate, batch size), prevent overfitting\n",
    "eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(200)) # 200 examples\n",
    "# Test dataset - Final, unbiased evaluation, used once after training is complete\n",
    "test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(200)) # 200 examples\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(eval_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Inspect a sample\n",
    "print(\"\\nSample from train dataset:\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load Pre-trained Tokenizer and Model ---\n",
    "print(\"\\nLoading tokenizer and model...\")\n",
    "model_name = \"distilbert/distilbert-base-uncased\" # A small, fast model\n",
    "\n",
    "# Loads tokenizer associated with DistilBERT model\n",
    "# this tokenizer knows to convert raw text into numberical:\n",
    "# input_ids, attention_mask, token_type_ids\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=dataset[\"train\"].features[\"label\"].num_classes # Automatically get number of labels\n",
    ")\n",
    "\n",
    "# Set up device for training (MPS for Apple Silicon if available, else CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Using Apple Silicon (MPS) for training: {device}\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using CUDA (GPU) for training: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using CPU for training: {device}\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Preprocess the Dataset ---\n",
    "print(\"\\nTokenizing and preprocessing dataset...\")\n",
    "\n",
    "# Simple function to tokenize the text field\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Apply tokenization to the entire dataset (batches for efficiency)\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Rename the 'label' column to 'labels' for the Trainer\n",
    "# Often needed for Hugging Face Trainer class\n",
    "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_test_dataset = tokenized_test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Set the format to PyTorch tensors, required for training with Pytorch\n",
    "tokenized_train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_eval_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue with transformers and accelerate versions in the environment, reinstalled with conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "print(f'Accelerate: {accelerate.__version__}')\n",
    "print(f'Transformers: {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Define Metrics ---\n",
    "print(\"\\nDefining evaluation metrics...\")\n",
    "# These are standard metrics to load\n",
    "metric = evaluate.load(\"accuracy\") # You can add more like \"f1\", \"precision\", \"recall\"\n",
    "\n",
    "# Function is required by Trainer to calculate metrics during evaluation\n",
    "# logits are the model's predictions\n",
    "# labels are the true labels\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# --- 5. Configure Training Arguments ---\n",
    "print(\"\\nSetting up Training Arguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",               # Output directory for model checkpoints and logs\n",
    "    num_train_epochs=3,                   # Number of training epochs (keep low for quick run)\n",
    "    per_device_train_batch_size=16,       # Batch size per device during training\n",
    "    per_device_eval_batch_size=16,        # Batch size for evaluation\n",
    "    warmup_steps=100,                     # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                    # Strength of weight decay\n",
    "    logging_dir=\"./logs\",                 # Directory for storing logs\n",
    "    logging_steps=50,                     # Log every X updates steps\n",
    "    eval_strategy=\"epoch\",                # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",                # Save model at the end of each epoch\n",
    "    load_best_model_at_end=True,          # Load the best model at the end of training\n",
    "    metric_for_best_model=\"accuracy\",     # Metric to use to compare models\n",
    "    report_to=\"none\",                     # Don't report to any online tracker (e.g., wandb, mlflow)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Create and Train the Trainer ---\n",
    "# Trainer is the core class for training models with Hugging Face\n",
    "print(\"\\nInitializing and training the Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer, # Pass tokenizer to handle padding dynamically in batches\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results Summary\n",
    "\n",
    "`TrainOutput(global_step=189, training_loss=1.1334309249958665, metrics={'train_runtime': 293.2748, 'train_samples_per_second': 10.229, 'train_steps_per_second': 0.644, 'total_flos': 397430544384000.0, 'train_loss': 1.1334309249958665, 'epoch': 3.0})`\n",
    "\n",
    "### Training Metrics Overview\n",
    "|Metric|Value|Assessment|\n",
    "|-------|----|----------|\n",
    "|Final Training Loss|1.133|Moderate, could use adjusted learning rate, more epochs, etc.|\n",
    "|Training Steps|189|Completed successfully|\n",
    "|Epochs Completed|3.0|Full Cycle complete|\n",
    "\n",
    "### Performance Metrics\n",
    "|Performance Indicator|Value|Notes|\n",
    "|---|---|----|\n",
    "|Total Runtime|293.27 seconds/~5 min|Reasonable for small dataset|\n",
    "|Samples/Second|10.23|Training Throughput|\n",
    "|Steps/Second|.644|Processing Speed|\n",
    "|Total FLOPs|397.4 trillion|Computational operations|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Evaluate the Trained Model ---\n",
    "print(\"\\nEvaluating the model on the test set...\")\n",
    "results = trainer.evaluate(tokenized_test_dataset)\n",
    "print(f\"Test Set Results: {results}\")\n",
    "\n",
    "# --- 8. Make Predictions (Optional) ---\n",
    "print(\"\\nMaking predictions on a sample...\")\n",
    "# Get some texts from the test set\n",
    "sample_texts = [test_dataset[\"text\"][i] for i in range(5)]\n",
    "sample_labels = [test_dataset[\"label\"][i] for i in range(5)]\n",
    "\n",
    "# Predict\n",
    "predictions = trainer.predict(tokenized_test_dataset.select(range(5)))\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# Map label IDs back to names (if you have them)\n",
    "label_names = dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i, text in enumerate(sample_texts):\n",
    "    true_label_name = label_names[sample_labels[i]]\n",
    "    predicted_label_name = label_names[predicted_labels[i]]\n",
    "    print(f\"Text: \\\"{text}\\\"\")\n",
    "    print(f\"True Label: {true_label_name}, Predicted Label: {predicted_label_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Results folder, is a checkpoint for each epoch (3). Split up by number of training steps (189).\n",
    "\n",
    "Files in each checkpoint:\n",
    "\n",
    "## Model Files\n",
    "|File|Purpose|Size|\n",
    "|---|---|-----|\n",
    "| model.safetensors | model weights | largest file|\n",
    "|config.json|model architecture and hyperparameters|Small|\n",
    "\n",
    "## Tokenizer files\n",
    "|File|Purpose|\n",
    "|---|---|\n",
    "| tokenizer.json | Tokenizer vocabulary and merges |\n",
    "|tokenizer_config.json|Tokenizer settings|\n",
    "|special_tokens_map.json|Special tokens (CLS, SEP, PAD, etc)|\n",
    "|vocab.txt|vocab file (for some tokenizers)|\n",
    "\n",
    "## Training State Files\n",
    "|File | Purpose | When You Need It| \n",
    "|---|---|---|\n",
    "|training_args.bin |Your TrainingArguments settings | Resuming training| \n",
    "|trainer_state.json | Training progress, loss history | Resuming training|\n",
    "|optimizer.pt | Optimizer state (Adam, etc.) | Resuming training| \n",
    "| scheduler.pt | Learning rate scheduler state| Resuming training |\n",
    "| rng_state.pth | Random number generator state | Reproducible resuming |\n",
    "\n",
    "## Important:\n",
    "- Use the below to resume training, now that you have these files:\n",
    "\n",
    "```python\n",
    "# Load for inference - only needs model + tokenizer files\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./results/checkpoint-189\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./results/checkpoint-189\")\n",
    "\n",
    "# Now you can make predictions\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
